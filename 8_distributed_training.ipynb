{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Fraud Detection using Codeflare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we will go over the basics of the Ray Job Submission Client in the SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Authenticate to the cluster either using the SDK or OpenShift console login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To launch a Ray cluster, you will need to authenticate yourself against the OpenShift cluster.\n",
    "# Run this cell to get the full instructions.\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "NOTEBOOK_ARGS = os.environ.get('NOTEBOOK_ARGS', '')\n",
    "match = re.search(r'\"hub_host\":\"https://.*?(apps\\.[^\"]+)\"', NOTEBOOK_ARGS)\n",
    "hub_host_value = match.group(1)\n",
    "\n",
    "login_url = 'https://oauth-openshift.' + hub_host_value + \"/oauth/token/request\"\n",
    "\n",
    "print('Open the following URL to get your authentication token.')\n",
    "print('Authenticate, then click on \"Display token\", and copy the content of the line under \"Log in with this token\"')\n",
    "print('You can then come back here and paste this content in the next cell.')\n",
    "print('Login URL: '+login_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!oc login --token=sha256~XXXX --server=https://XXXX \n",
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration of our Ray cluster\n",
    "name = \"raycluster-cpu\"\n",
    "namespace = !cat /var/run/secrets/kubernetes.io/serviceaccount/namespace\n",
    "namespace = namespace[0]\n",
    "\n",
    "ray_version = \"2.33.0\"\n",
    "python_version = \"py311\"\n",
    "cuda_version = \"cu118\"\n",
    "image = f\"docker.io/rayproject/ray:{ray_version}-{python_version}-{cuda_version}\"\n",
    "print(name, namespace, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SDK will try to find the name of your default local queue based on the annotation \"kueue.x-k8s.io/default-queue\": \"true\" unless you specify the local queue manually below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from codeflare_sdk import Cluster, ClusterConfiguration\n",
    "\n",
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name=name,\n",
    "    namespace=namespace,\n",
    "    head_gpus=0,\n",
    "    num_gpus=0,\n",
    "    num_workers=2,\n",
    "    min_cpus=1,\n",
    "    max_cpus=6,\n",
    "    min_memory=4,\n",
    "    max_memory=28,\n",
    "    image=image,\n",
    "    write_to_file=True, # When enabled Ray Cluster yaml files are written to /HOME/.codeflare/resources \n",
    "    # local_queue=\"local-queue-name\" # Specify the local queue manually\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring up the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.up()\n",
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively, get a running cluster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from codeflare_sdk import get_cluster\n",
    "\n",
    "cluster = get_cluster(name, namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "import utils.s3\n",
    "\n",
    "utils.s3.upload_directory_to_s3(\"data\", \"data\")\n",
    "print(\"---\")\n",
    "utils.s3.list_objects(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Job Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize the Cluster Job Client \n",
    "* Provide an entrypoint command directed to your job script\n",
    "* Set up your [runtime environment](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#runtime-environments)\n",
    "\n",
    "Some common runtime environment configurations include:\n",
    "\n",
    "```python\n",
    "runtime_env={\n",
    "    \"working_dir\": \"./\", # relative path to files uploaded to the job\n",
    "    \"excludes\": [\"local_data/\"], # directories and files to exclude from being uploaded to the job\n",
    "    \"pip\": [\"boto3\", \"botocore\"], # can also be a string path to a requirements.txt file\n",
    "    \"env_vars\": {\n",
    "        \"MY_ENV_VAR\": \"MY_ENV_VAR_VALUE\",\n",
    "        \"MY_ENV_VAR_2\": os.environ.get(\"MY_ENV_VAR_2\"),\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Job Submission Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = cluster.job_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if there are any existing jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.list_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Some Sample Runtime Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for job_details in client.list_jobs():\n",
    "    print(job_details.submission_id)\n",
    "    client.delete_job(job_details.submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# script = \"test_data_loader.py\"\n",
    "script = \"train_cpu.py\"\n",
    "runtime_env = {\n",
    "    \"working_dir\": \"./ray-scripts\",\n",
    "    \"excludes\": [],\n",
    "    \"pip\": \"./ray-scripts/requirements.txt\",\n",
    "    \"env_vars\": {\n",
    "        \"AWS_ACCESS_KEY_ID\": os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        \"AWS_SECRET_ACCESS_KEY\": os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"AWS_S3_ENDPOINT\": os.environ.get(\"AWS_S3_ENDPOINT\"),\n",
    "        \"AWS_DEFAULT_REGION\": os.environ.get(\"AWS_DEFAULT_REGION\"),\n",
    "        \"AWS_S3_BUCKET\": os.environ.get(\"AWS_S3_BUCKET\"),\n",
    "        \"TRAIN_DATA\": \"data/train.csv\",\n",
    "        \"VALIDATE_DATA\": \"data/validate.csv\",\n",
    "        \"MODEL_OUTPUT\": \"models/fraud/1/\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit the configured job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_id = client.submit_job(\n",
    "    entrypoint=f\"python {script}\",\n",
    "    runtime_env=runtime_env,\n",
    ")\n",
    "\n",
    "print(submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query Important Job Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the job's status\n",
    "print(client.get_job_status(submission_id), \"\\n\")\n",
    "\n",
    "# Get job related info\n",
    "print(client.get_job_info(submission_id), \"\\n\")\n",
    "\n",
    "# Get the job's logs\n",
    "print(client.get_job_logs(submission_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through the logs of a job \n",
    "async for lines in client.tail_job_logs(submission_id):\n",
    "    print(lines, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Delete a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.stop_job(submission_id)\n",
    "client.delete_job(submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
