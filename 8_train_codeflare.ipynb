{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting Jobs to Kuberay - GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we will go over the basics of the Ray Job Submission Client in the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codeflare-sdk             0.16.1\n",
      "codeflare-torchx          0.6.0.dev2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep codeflare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Authenticate to the cluster either using the SDK or OpenShift console login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authentication object for user permissions\n",
    "# IF unused, SDK will automatically check for default kubeconfig, then in-cluster config\n",
    "\n",
    "# KubeConfigFileAuthentication can also be used to specify kubeconfig path manually\n",
    "# auth = TokenAuthentication(\n",
    "#     token = \"XXXXX\",\n",
    "#     server = \"XXXXX\",\n",
    "#     skip_tls=False\n",
    "# )\n",
    "# auth.login()\n",
    "\n",
    "# Paste in the oc login command from\n",
    "# the OpenShift console \"Copy login command\" after the \"!\"\n",
    "!oc login --token=sha256~XXXX --server=https://XXXX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raycluster-gpu chase-dev docker.io/rayproject/ray:2.33.0-py311-cu118\n"
     ]
    }
   ],
   "source": [
    "# Configuration of our Ray cluster\n",
    "name = \"raycluster-gpu\"\n",
    "namespace = !cat /var/run/secrets/kubernetes.io/serviceaccount/namespace\n",
    "namespace = namespace[0]\n",
    "\n",
    "# We can use the standard codeflare image or one of the newer Ray images\n",
    "# or we can use one of the newer Ray images\n",
    "ray_version = \"2.33.0\"\n",
    "python_version = \"py311\"\n",
    "cuda_version = \"cu118\"\n",
    "image = f\"docker.io/rayproject/ray:{ray_version}-{python_version}-{cuda_version}\"\n",
    "# image = \"rayproject/ray-ml:2.23.0-py311-gpu\"\n",
    "\n",
    "# image = \"quay.io/project-codeflare/ray:latest-py39-cu118\"\n",
    "# image = \"rayproject/ray-ml:2.23.0-py311-gpu\"\n",
    "# image = \"docker.io/rayproject/ray:2.23.0-py39-cu121\"\n",
    "\n",
    "print(name, namespace, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                  CLUSTERQUEUE    PENDING WORKLOADS   ADMITTED WORKLOADS\n",
      "local-queue-default   cluster-queue   0                   2\n"
     ]
    }
   ],
   "source": [
    "!oc get localqueue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SDK will try to find the name of your default local queue based on the annotation \"kueue.x-k8s.io/default-queue\": \"true\" unless you specify the local queue manually below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name=name,\n",
    "    namespace=namespace,\n",
    "    head_gpus=1,\n",
    "    num_gpus=1,\n",
    "    num_workers=2,\n",
    "    min_cpus=1,\n",
    "    max_cpus=6,\n",
    "    min_memory=8,\n",
    "    max_memory=28,\n",
    "    image=image,\n",
    "    write_to_file=True, # When enabled Ray Cluster yaml files are written to /HOME/.codeflare/resources \n",
    "    # local_queue=\"local-queue-name\" # Specify the local queue manually\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "file_path = os.path.expanduser(f\"~/.codeflare/resources/{name}.yaml\")\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    try:\n",
    "        mod_cluster = yaml.safe_load(file)\n",
    "        # pprint(cluster)  # This will print the content of the YAML file as a dictionary\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "# mod_cluster[\"spec\"][\"headGroupSpec\"][\"template\"][\"spec\"][\"tolerations\"] = [{\n",
    "#     \"effect\": \"NoSchedule\",\n",
    "#     \"key\": \"nvidia.com/gpu\",\n",
    "#     \"operator\": \"Exists\",\n",
    "# }]\n",
    "\n",
    "# mod_cluster[\"spec\"][\"workerGroupSpecs\"][0][\"template\"][\"spec\"][\"tolerations\"] = [{\n",
    "#     \"effect\": \"NoSchedule\",\n",
    "#     \"key\": \"nvidia.com/gpu\",\n",
    "#     \"operator\": \"Exists\",\n",
    "# }]\n",
    "\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    yaml.dump(mod_cluster, file)\n",
    "\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    try:\n",
    "        check_cluster = yaml.safe_load(file)\n",
    "        # print(check_cluster[\"spec\"][\"headGroupSpec\"][\"template\"][\"spec\"][\"tolerations\"])\n",
    "        # print(check_cluster[\"spec\"][\"workerGroupSpecs\"][0][\"template\"][\"spec\"][\"tolerations\"])\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bring up the cluster\n",
    "cluster.up()\n",
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively, get a running cluster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml resources loaded for raycluster-gpu\n"
     ]
    }
   ],
   "source": [
    "from codeflare_sdk import get_cluster\n",
    "# \n",
    "cluster = get_cluster(name, namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     </span><span style=\"font-weight: bold; font-style: italic\"> ðŸš€ CodeFlare Cluster Details ðŸš€</span><span style=\"font-style: italic\">                      </span>\n",
       "<span style=\"font-weight: bold\">                                                                           </span>\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #008000; font-weight: bold\">Name</span>                                                                â”‚ \n",
       " â”‚   <span style=\"font-weight: bold; text-decoration: underline\">raycluster-gpu</span>                                          Active âœ…   â”‚ \n",
       " â”‚                                                                       â”‚ \n",
       " â”‚   <span style=\"font-weight: bold\">URI:</span> ray://raycluster-gpu-head-svc.chase-dev.svc:10001              â”‚ \n",
       " â”‚                                                                       â”‚ \n",
       " â”‚   <a href=\"https://ray-dashboard-raycluster-gpu-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">DashboardðŸ”—</span></a>                                                         â”‚ \n",
       " â”‚                                                                       â”‚ \n",
       " â”‚  <span style=\"font-style: italic\">                     Cluster Resources                     </span>          â”‚ \n",
       " â”‚   â•­â”€â”€ Workers â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker specs(each) â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®           â”‚ \n",
       " â”‚   â”‚ <span style=\"font-weight: bold\"> # Workers </span> â”‚  â”‚ <span style=\"font-weight: bold\"> Memory      CPU         GPU        </span> â”‚           â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> â”‚           â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\"> 2         </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\"> 8G~28G     </span><span style=\"color: #800080; text-decoration-color: #800080\"> 1           1          </span> â”‚           â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> â”‚           â”‚ \n",
       " â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯           â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                     \u001b[0m\u001b[1;3m ðŸš€ CodeFlare Cluster Details ðŸš€\u001b[0m\u001b[3m                      \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m                                                                         \u001b[0m\u001b[1m \u001b[0m\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   \u001b[1;37;42mName\u001b[0m                                                                â”‚ \n",
       " â”‚   \u001b[1;4mraycluster-gpu\u001b[0m                                          Active âœ…   â”‚ \n",
       " â”‚                                                                       â”‚ \n",
       " â”‚   \u001b[1mURI:\u001b[0m ray://raycluster-gpu-head-svc.chase-dev.svc:10001              â”‚ \n",
       " â”‚                                                                       â”‚ \n",
       " â”‚   \u001b]8;id=723396;https://ray-dashboard-raycluster-gpu-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com\u001b\\\u001b[4;34mDashboardðŸ”—\u001b[0m\u001b]8;;\u001b\\                                                         â”‚ \n",
       " â”‚                                                                       â”‚ \n",
       " â”‚  \u001b[3m                     Cluster Resources                     \u001b[0m          â”‚ \n",
       " â”‚   â•­â”€â”€ Workers â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker specs(each) â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®           â”‚ \n",
       " â”‚   â”‚ \u001b[1m \u001b[0m\u001b[1m# Workers\u001b[0m\u001b[1m \u001b[0m â”‚  â”‚ \u001b[1m \u001b[0m\u001b[1mMemory    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCPU       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mGPU       \u001b[0m\u001b[1m \u001b[0m â”‚           â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m â”‚           â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m2        \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m8G~28G    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m1         \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m1         \u001b[0m\u001b[35m \u001b[0m â”‚           â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m â”‚           â”‚ \n",
       " â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯           â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RayCluster(name='raycluster-gpu', status=<RayClusterStatus.READY: 'ready'>, head_cpus=2, head_mem='8G', head_gpu=0, workers=2, worker_mem_min='8G', worker_mem_max='28G', worker_cpu='1', worker_gpu=1, namespace='chase-dev', dashboard='https://ray-dashboard-raycluster-gpu-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.csv -> data/train.csv\n",
      "data/validate.csv -> data/validate.csv\n",
      "data/card_transdata.csv -> data/card_transdata.csv\n",
      "data/test.csv -> data/test.csv\n",
      "data/card_transdata.csv\n",
      "data/test.csv\n",
      "data/train.csv\n",
      "data/validate.csv\n",
      "generated-images/000.png\n",
      "models/Meta-Llama-3-8B/LICENSE\n",
      "models/Meta-Llama-3-8B/README.md\n",
      "models/Meta-Llama-3-8B/USE_POLICY.md\n",
      "models/Meta-Llama-3-8B/config.json\n",
      "models/Meta-Llama-3-8B/generation_config.json\n",
      "models/Meta-Llama-3-8B/model-00001-of-00004.safetensors\n",
      "models/Meta-Llama-3-8B/model-00002-of-00004.safetensors\n",
      "models/Meta-Llama-3-8B/model-00003-of-00004.safetensors\n",
      "models/Meta-Llama-3-8B/model-00004-of-00004.safetensors\n",
      "models/Meta-Llama-3-8B/model.safetensors.index.json\n",
      "models/Meta-Llama-3-8B/original/consolidated.00.pth\n",
      "models/Meta-Llama-3-8B/original/params.json\n",
      "models/Meta-Llama-3-8B/original/tokenizer.model\n",
      "models/Meta-Llama-3-8B/special_tokens_map.json\n",
      "models/Meta-Llama-3-8B/tokenizer.json\n",
      "models/Meta-Llama-3-8B/tokenizer_config.json\n",
      "models/Meta-Llama-3.1-8B-Instruct/LICENSE\n",
      "models/Meta-Llama-3.1-8B-Instruct/README.md\n",
      "models/Meta-Llama-3.1-8B-Instruct/USE_POLICY.md\n",
      "models/Meta-Llama-3.1-8B-Instruct/config.json\n",
      "models/Meta-Llama-3.1-8B-Instruct/generation_config.json\n",
      "models/Meta-Llama-3.1-8B-Instruct/model-00001-of-00004.safetensors\n",
      "models/Meta-Llama-3.1-8B-Instruct/model-00002-of-00004.safetensors\n",
      "models/Meta-Llama-3.1-8B-Instruct/model-00003-of-00004.safetensors\n",
      "models/Meta-Llama-3.1-8B-Instruct/model-00004-of-00004.safetensors\n",
      "models/Meta-Llama-3.1-8B-Instruct/model.safetensors.index.json\n",
      "models/Meta-Llama-3.1-8B-Instruct/original/consolidated.00.pth\n",
      "models/Meta-Llama-3.1-8B-Instruct/original/params.json\n",
      "models/Meta-Llama-3.1-8B-Instruct/original/tokenizer.model\n",
      "models/Meta-Llama-3.1-8B-Instruct/special_tokens_map.json\n",
      "models/Meta-Llama-3.1-8B-Instruct/tokenizer.json\n",
      "models/Meta-Llama-3.1-8B-Instruct/tokenizer_config.json\n",
      "models/notebook-output/redhat-dog/checkpoint-500/optimizer.bin\n",
      "models/notebook-output/redhat-dog/checkpoint-500/random_states_0.pkl\n",
      "models/notebook-output/redhat-dog/checkpoint-500/scheduler.bin\n",
      "models/notebook-output/redhat-dog/checkpoint-500/unet/config.json\n",
      "models/notebook-output/redhat-dog/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
      "models/notebook-output/redhat-dog/feature_extractor/preprocessor_config.json\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1721854272.5010345/events.out.tfevents.1721854272.pytorch-0.709.1\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1721854272.5025876/hparams.yml\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/events.out.tfevents.1721854272.pytorch-0.709.0\n",
      "models/notebook-output/redhat-dog/model_index.json\n",
      "models/notebook-output/redhat-dog/scheduler/scheduler_config.json\n",
      "models/notebook-output/redhat-dog/text_encoder/config.json\n",
      "models/notebook-output/redhat-dog/text_encoder/model.safetensors\n",
      "models/notebook-output/redhat-dog/tokenizer/merges.txt\n",
      "models/notebook-output/redhat-dog/tokenizer/special_tokens_map.json\n",
      "models/notebook-output/redhat-dog/tokenizer/tokenizer_config.json\n",
      "models/notebook-output/redhat-dog/tokenizer/vocab.json\n",
      "models/notebook-output/redhat-dog/unet/config.json\n",
      "models/notebook-output/redhat-dog/unet/diffusion_pytorch_model.safetensors\n",
      "models/notebook-output/redhat-dog/vae/config.json\n",
      "models/notebook-output/redhat-dog/vae/diffusion_pytorch_model.safetensors\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "import utils.s3\n",
    "\n",
    "utils.s3.upload_directory_to_s3(\"data\", \"data\")\n",
    "utils.s3.list_objects(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Job Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize the Cluster Job Client \n",
    "* Provide an entrypoint command directed to your job script\n",
    "* Set up your [runtime environment](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#runtime-environments)\n",
    "\n",
    "Some common runtime environment configurations include:\n",
    "\n",
    "```python\n",
    "runtime_env={\n",
    "    \"working_dir\": \"./\", # relative path to files uploaded to the job\n",
    "    \"excludes\": [\"local_data/\"], # directories and files to exclude from being uploaded to the job\n",
    "    \"pip\": [\"boto3\", \"botocore\"], # can also be a string path to a requirements.txt file\n",
    "    \"env_vars\": {\n",
    "        \"MY_ENV_VAR\": \"MY_ENV_VAR_VALUE\",\n",
    "        \"MY_ENV_VAR_2\": os.environ.get(\"MY_ENV_VAR_2\"),\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Job Submission Client\n",
    "\"\"\"\n",
    "The SDK will automatically gather the dashboard address and authenticate using the Ray Job Submission Client\n",
    "\"\"\"\n",
    "client = cluster.job_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if there are any existing jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JobDetails(type=<JobType.SUBMISSION: 'SUBMISSION'>, job_id='07000000', submission_id='raysubmit_bp9anRkY8cLxFaQV', driver_info=DriverInfo(id='07000000', node_ip_address='10.128.42.23', pid='22072'), status=<JobStatus.FAILED: 'FAILED'>, entrypoint='python mnist_fashion_2.py', message='Job entrypoint command failed with exit code 1, last available logs (truncated to 20,000 chars):\\n\\nTraceback (most recent call last):\\n  File \"/tmp/ray/session_2024-08-02_10-07-26_937748_1/runtime_resources/working_dir_files/_ray_pkg_78756766d4a0f4f0/mnist_fashion_2.py\", line 74, in <module>\\n    result = trainer.fit()\\n             ^^^^^^^^^^^^^\\n  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/train/base_trainer.py\", line 638, in fit\\n    raise TrainingFailedError(\\nray.train.base_trainer.TrainingFailedError: The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"/home/ray/ray_results/TorchTrainer_2024-08-02_11-34-32\")`.\\nTo start a new run that will retry on training failures, set `train.RunConfig(failure_config=train.FailureConfig(max_failures))` in the Trainer\\'s `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries.\\n', error_type=None, start_time=1722623668311, end_time=1722623701118, metadata={}, runtime_env={'working_dir': 'gcs://_ray_pkg_78756766d4a0f4f0.zip', 'pip': {'packages': ['boto3', 'botocore', 'torch', 'torchvision'], 'pip_check': False}, 'env_vars': {'AWS_ACCESS_KEY_ID': 'minio', 'AWS_SECRET_ACCESS_KEY': 'miniocfc', 'AWS_S3_ENDPOINT': 'https://minio-s3-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com', 'AWS_DEFAULT_REGION': 'us-east-1', 'AWS_S3_BUCKET': 'my-storage', 'HF_USER': 'cfchase', 'HF_TOKEN': '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'}, '_ray_commit': 'b4bba4717f5ba04ee25580fe8f88eed63ef0c5dc'}, driver_agent_http_address='http://10.128.42.23:52365', driver_node_id='32334e986a1a2ee7f37e27bd4eb8f577a64738816f38f793b9188c57'),\n",
       " JobDetails(type=<JobType.SUBMISSION: 'SUBMISSION'>, job_id='03000000', submission_id='raysubmit_fnp6UJSVB45Awtjx', driver_info=DriverInfo(id='03000000', node_ip_address='10.128.42.23', pid='11774'), status=<JobStatus.SUCCEEDED: 'SUCCEEDED'>, entrypoint='python s3_list.py', message='Job finished successfully.', error_type=None, start_time=1722621275242, end_time=1722621282446, metadata={}, runtime_env={'working_dir': 'gcs://_ray_pkg_36e7500f87fb849a.zip', 'excludes': ['data/'], 'pip': {'packages': ['boto3', 'botocore'], 'pip_check': False}, 'env_vars': {'AWS_ACCESS_KEY_ID': 'minio', 'AWS_SECRET_ACCESS_KEY': 'miniocfc', 'AWS_S3_ENDPOINT': 'https://minio-s3-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com', 'AWS_DEFAULT_REGION': 'us-east-1', 'AWS_S3_BUCKET': 'my-storage'}, '_ray_commit': 'b4bba4717f5ba04ee25580fe8f88eed63ef0c5dc'}, driver_agent_http_address='http://10.128.42.23:52365', driver_node_id='32334e986a1a2ee7f37e27bd4eb8f577a64738816f38f793b9188c57'),\n",
       " JobDetails(type=<JobType.SUBMISSION: 'SUBMISSION'>, job_id='05000000', submission_id='raysubmit_wUipHDbVTfeBvkTH', driver_info=DriverInfo(id='05000000', node_ip_address='10.128.42.23', pid='12999'), status=<JobStatus.SUCCEEDED: 'SUCCEEDED'>, entrypoint='python s3_list.py', message='Job finished successfully.', error_type=None, start_time=1722621430423, end_time=1722621512439, metadata={}, runtime_env={'working_dir': 'gcs://_ray_pkg_36e7500f87fb849a.zip', 'excludes': ['data/'], 'pip': {'packages': ['boto3', 'botocore', 'torch', 'torchvision'], 'pip_check': False}, 'env_vars': {'AWS_ACCESS_KEY_ID': 'minio', 'AWS_SECRET_ACCESS_KEY': 'miniocfc', 'AWS_S3_ENDPOINT': 'https://minio-s3-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com', 'AWS_DEFAULT_REGION': 'us-east-1', 'AWS_S3_BUCKET': 'my-storage', 'HF_USER': 'cfchase', 'HF_TOKEN': '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'}, '_ray_commit': 'b4bba4717f5ba04ee25580fe8f88eed63ef0c5dc'}, driver_agent_http_address='http://10.128.42.23:52365', driver_node_id='32334e986a1a2ee7f37e27bd4eb8f577a64738816f38f793b9188c57'),\n",
       " JobDetails(type=<JobType.SUBMISSION: 'SUBMISSION'>, job_id='04000000', submission_id='raysubmit_DuX1bUNXN1JQML2z', driver_info=DriverInfo(id='04000000', node_ip_address='10.128.42.23', pid='12226'), status=<JobStatus.SUCCEEDED: 'SUCCEEDED'>, entrypoint='python s3_list.py', message='Job finished successfully.', error_type=None, start_time=1722621360196, end_time=1722621363818, metadata={}, runtime_env={'working_dir': 'gcs://_ray_pkg_36e7500f87fb849a.zip', 'excludes': ['data/'], 'pip': {'packages': ['boto3', 'botocore'], 'pip_check': False}, 'env_vars': {'AWS_ACCESS_KEY_ID': 'minio', 'AWS_SECRET_ACCESS_KEY': 'miniocfc', 'AWS_S3_ENDPOINT': 'https://minio-s3-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com', 'AWS_DEFAULT_REGION': 'us-east-1', 'AWS_S3_BUCKET': 'my-storage', 'HF_USER': 'cfchase', 'HF_TOKEN': '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'}, '_ray_commit': 'b4bba4717f5ba04ee25580fe8f88eed63ef0c5dc'}, driver_agent_http_address='http://10.128.42.23:52365', driver_node_id='32334e986a1a2ee7f37e27bd4eb8f577a64738816f38f793b9188c57'),\n",
       " JobDetails(type=<JobType.SUBMISSION: 'SUBMISSION'>, job_id='06000000', submission_id='raysubmit_9VHRrwN3Jqd8Sf6T', driver_info=DriverInfo(id='06000000', node_ip_address='10.128.42.23', pid='20182'), status=<JobStatus.SUCCEEDED: 'SUCCEEDED'>, entrypoint='python mnist_fashion.py', message='Job finished successfully.', error_type=None, start_time=1722623259688, end_time=1722623299911, metadata={}, runtime_env={'working_dir': 'gcs://_ray_pkg_9db31991855103dc.zip', 'pip': {'packages': ['boto3', 'botocore', 'torch', 'torchvision'], 'pip_check': False}, 'env_vars': {'AWS_ACCESS_KEY_ID': 'minio', 'AWS_SECRET_ACCESS_KEY': 'miniocfc', 'AWS_S3_ENDPOINT': 'https://minio-s3-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com', 'AWS_DEFAULT_REGION': 'us-east-1', 'AWS_S3_BUCKET': 'my-storage', 'HF_USER': 'cfchase', 'HF_TOKEN': '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'}, '_ray_commit': 'b4bba4717f5ba04ee25580fe8f88eed63ef0c5dc'}, driver_agent_http_address='http://10.128.42.23:52365', driver_node_id='32334e986a1a2ee7f37e27bd4eb8f577a64738816f38f793b9188c57')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all existing jobs\n",
    "client.list_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Some Sample Runtime Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "script = \"train.py\"\n",
    "runtime_env = {\n",
    "    \"working_dir\": \"./ray-scripts\",\n",
    "    \"excludes\": [],\n",
    "    \"pip\": \"./ray-scripts/requirements.txt\",\n",
    "    \"env_vars\": {\n",
    "        \"HF_USER\": os.environ.get(\"HF_USER\"),\n",
    "        \"HF_TOKEN\": os.environ.get(\"HF_TOKEN\"),\n",
    "        \"AWS_ACCESS_KEY_ID\": os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        \"AWS_SECRET_ACCESS_KEY\": os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"AWS_S3_ENDPOINT\": os.environ.get(\"AWS_S3_ENDPOINT\"),\n",
    "        \"AWS_DEFAULT_REGION\": os.environ.get(\"AWS_DEFAULT_REGION\"),\n",
    "        \"AWS_S3_BUCKET\": os.environ.get(\"AWS_S3_BUCKET\")\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit the configured job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 20:48:54,064\tINFO dashboard_sdk.py:338 -- Uploading package gcs://_ray_pkg_f741ade6e8726522.zip.\n",
      "2024-08-02 20:48:54,065\tINFO packaging.py:518 -- Creating a file package for local directory './ray-scripts'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raysubmit_GA2ShMGYXdwYWcKN\n"
     ]
    }
   ],
   "source": [
    "submission_id = client.submit_job(\n",
    "    entrypoint=f\"python {script}\",\n",
    "    runtime_env=runtime_env,\n",
    ")\n",
    "\n",
    "print(submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query Important Job Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED \n",
      "\n",
      "type=<JobType.SUBMISSION: 'SUBMISSION'> job_id=None submission_id='raysubmit_aR6kczrLJFcWUF4Y' driver_info=None status=<JobStatus.FAILED: 'FAILED'> entrypoint='python train.py' message='Job entrypoint command failed with exit code 1, last available logs (truncated to 20,000 chars):\\n2024-08-02 13:44:44,585\\tINFO job_manager.py:531 -- Runtime env is setting up.\\n  File \"/tmp/ray/session_2024-08-02_10-07-26_937748_1/runtime_resources/working_dir_files/_ray_pkg_6af8ab6f7aa01120/train.py\", line 95\\n    storage_path=f\"s3://{bucket_name}/ray/fraud-training/\"        \\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\\n' error_type=None start_time=1722631484583 end_time=1722631487661 metadata={} runtime_env={'working_dir': 'gcs://_ray_pkg_6af8ab6f7aa01120.zip', 'pip': {'packages': ['boto3', 'botocore', 'torch', 'torchvision'], 'pip_check': False}, 'env_vars': {'HF_USER': 'cfchase', 'HF_TOKEN': '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', 'AWS_ACCESS_KEY_ID': 'minio', 'AWS_SECRET_ACCESS_KEY': 'miniocfc', 'AWS_S3_ENDPOINT': 'https://minio-s3-chase-dev.apps.dev.rhoai.rh-aiservices-bu.com', 'AWS_DEFAULT_REGION': 'us-east-1', 'AWS_S3_BUCKET': 'my-storage'}, '_ray_commit': 'b4bba4717f5ba04ee25580fe8f88eed63ef0c5dc'} driver_agent_http_address='http://10.128.42.23:52365' driver_node_id='32334e986a1a2ee7f37e27bd4eb8f577a64738816f38f793b9188c57' \n",
      "\n",
      "2024-08-02 13:44:44,585\tINFO job_manager.py:531 -- Runtime env is setting up.\n",
      "  File \"/tmp/ray/session_2024-08-02_10-07-26_937748_1/runtime_resources/working_dir_files/_ray_pkg_6af8ab6f7aa01120/train.py\", line 95\n",
      "    storage_path=f\"s3://{bucket_name}/ray/fraud-training/\"        \n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "SyntaxError: invalid syntax. Perhaps you forgot a comma?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the job's status\n",
    "print(client.get_job_status(submission_id), \"\\n\")\n",
    "\n",
    "# Get job related info\n",
    "print(client.get_job_info(submission_id), \"\\n\")\n",
    "\n",
    "# Get the job's logs\n",
    "print(client.get_job_logs(submission_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through the logs of a job \n",
    "async for lines in client.tail_job_logs(submission_id):\n",
    "    print(lines, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Delete a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(client.list_jobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.stop_job(submission_id)\n",
    "\n",
    "client.delete_job(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(client.list_jobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
