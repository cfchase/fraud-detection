{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Fraud Detection using Codeflare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we will go over the basics of the Ray Job Submission Client in the SDK"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip list | grep codeflare\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Authenticate to the cluster either using the SDK or OpenShift console login"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create authentication object for user permissions\n",
    "# IF unused, SDK will automatically check for default kubeconfig, then in-cluster config\n",
    "\n",
    "# KubeConfigFileAuthentication can also be used to specify kubeconfig path manually\n",
    "# auth = TokenAuthentication(\n",
    "#     token = \"XXXXX\",\n",
    "#     server = \"XXXXX\",\n",
    "#     skip_tls=False\n",
    "# )\n",
    "# auth.login()\n",
    "\n",
    "# Paste in the oc login command from\n",
    "# the OpenShift console \"Copy login command\" after the \"!\"\n",
    " !oc login --token=sha256~XXXX --server=https://XXXX "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Cluster"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configuration of our Ray cluster\n",
    "name = \"raycluster-cpu\"\n",
    "namespace = !cat /var/run/secrets/kubernetes.io/serviceaccount/namespace\n",
    "namespace = namespace[0]\n",
    "\n",
    "# We can use the standard codeflare image or one of the newer Ray images\n",
    "# or we can use one of the newer Ray images\n",
    "ray_version = \"2.33.0\"\n",
    "python_version = \"py311\"\n",
    "cuda_version = \"cu118\"\n",
    "image = f\"docker.io/rayproject/ray:{ray_version}-{python_version}-{cuda_version}\"\n",
    "# image = \"rayproject/ray-ml:2.23.0-py311-gpu\"\n",
    "\n",
    "# image = \"quay.io/project-codeflare/ray:latest-py39-cu118\"\n",
    "# image = \"rayproject/ray-ml:2.23.0-py311-gpu\"\n",
    "# image = \"docker.io/rayproject/ray:2.23.0-py39-cu121\"\n",
    "\n",
    "print(name, namespace, image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "!oc get localqueue"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SDK will try to find the name of your default local queue based on the annotation \"kueue.x-k8s.io/default-queue\": \"true\" unless you specify the local queue manually below\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name=name,\n",
    "    namespace=namespace,\n",
    "    head_gpus=0,\n",
    "    num_gpus=0,\n",
    "    num_workers=2,\n",
    "    min_cpus=1,\n",
    "    max_cpus=6,\n",
    "    min_memory=4,\n",
    "    max_memory=28,\n",
    "    image=image,\n",
    "    write_to_file=True, # When enabled Ray Cluster yaml files are written to /HOME/.codeflare/resources \n",
    "    # local_queue=\"local-queue-name\" # Specify the local queue manually\n",
    "))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "file_path = os.path.expanduser(f\"~/.codeflare/resources/{name}.yaml\")\n",
    "\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     try:\n",
    "#         mod_cluster = yaml.safe_load(file)\n",
    "#         # pprint(cluster)  # This will print the content of the YAML file as a dictionary\n",
    "#     except yaml.YAMLError as exc:\n",
    "#         print(exc)\n",
    "\n",
    "# mod_cluster[\"spec\"][\"headGroupSpec\"][\"template\"][\"spec\"][\"tolerations\"] = [{\n",
    "#     \"effect\": \"NoSchedule\",\n",
    "#     \"key\": \"nvidia.com/gpu\",\n",
    "#     \"operator\": \"Exists\",\n",
    "# }]\n",
    "\n",
    "# mod_cluster[\"spec\"][\"workerGroupSpecs\"][0][\"template\"][\"spec\"][\"tolerations\"] = [{\n",
    "#     \"effect\": \"NoSchedule\",\n",
    "#     \"key\": \"nvidia.com/gpu\",\n",
    "#     \"operator\": \"Exists\",\n",
    "# }]\n",
    "\n",
    "\n",
    "# with open(file_path, \"w\") as file:\n",
    "#     yaml.dump(mod_cluster, file)\n",
    "\n",
    "\n",
    "# with open(file_path, \"r\") as file:\n",
    "#     try:\n",
    "#         check_cluster = yaml.safe_load(file)\n",
    "#         # print(check_cluster[\"spec\"][\"headGroupSpec\"][\"template\"][\"spec\"][\"tolerations\"])\n",
    "#         # print(check_cluster[\"spec\"][\"workerGroupSpecs\"][0][\"template\"][\"spec\"][\"tolerations\"])\n",
    "#     except yaml.YAMLError as exc:\n",
    "#         print(exc)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bring up the cluster\n",
    "cluster.up()\n",
    "cluster.wait_ready()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively, get a running cluster object"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "from codeflare_sdk import get_cluster\n",
    "\n",
    "cluster = get_cluster(name, namespace=namespace)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "cluster.details()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "import utils.s3\n",
    "\n",
    "utils.s3.upload_directory_to_s3(\"data\", \"data\")\n",
    "print(\"---\")\n",
    "utils.s3.list_objects(\"data\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Job Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize the Cluster Job Client \n",
    "* Provide an entrypoint command directed to your job script\n",
    "* Set up your [runtime environment](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#runtime-environments)\n",
    "\n",
    "Some common runtime environment configurations include:\n",
    "\n",
    "```python\n",
    "runtime_env={\n",
    "    \"working_dir\": \"./\", # relative path to files uploaded to the job\n",
    "    \"excludes\": [\"local_data/\"], # directories and files to exclude from being uploaded to the job\n",
    "    \"pip\": [\"boto3\", \"botocore\"], # can also be a string path to a requirements.txt file\n",
    "    \"env_vars\": {\n",
    "        \"MY_ENV_VAR\": \"MY_ENV_VAR_VALUE\",\n",
    "        \"MY_ENV_VAR_2\": os.environ.get(\"MY_ENV_VAR_2\"),\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize the Job Submission Client\n",
    "\"\"\"\n",
    "The SDK will automatically gather the dashboard address and authenticate using the Ray Job Submission Client\n",
    "\"\"\"\n",
    "client = cluster.job_client"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if there are any existing jobs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# List all existing jobs\n",
    "client.list_jobs()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Some Sample Runtime Environments"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "# script = \"test_data_loader.py\"\n",
    "script = \"train_cpu.py\"\n",
    "runtime_env = {\n",
    "    \"working_dir\": \"./ray-scripts\",\n",
    "    \"excludes\": [],\n",
    "    \"pip\": \"./ray-scripts/requirements.txt\",\n",
    "    \"env_vars\": {\n",
    "        \"HF_USER\": os.environ.get(\"HF_USER\"),\n",
    "        \"HF_TOKEN\": os.environ.get(\"HF_TOKEN\"),\n",
    "        \"AWS_ACCESS_KEY_ID\": os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        \"AWS_SECRET_ACCESS_KEY\": os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"AWS_S3_ENDPOINT\": os.environ.get(\"AWS_S3_ENDPOINT\"),\n",
    "        \"AWS_DEFAULT_REGION\": os.environ.get(\"AWS_DEFAULT_REGION\"),\n",
    "        \"AWS_S3_BUCKET\": os.environ.get(\"AWS_S3_BUCKET\"),\n",
    "        \"CSV_FILE_PATH\": \"my-storage/data/train.csv\",\n",
    "    },\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit the configured job"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "submission_id = client.submit_job(\n",
    "    entrypoint=f\"python {script}\",\n",
    "    runtime_env=runtime_env,\n",
    ")\n",
    "\n",
    "print(submission_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query Important Job Information"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get the job's status\n",
    "print(client.get_job_status(submission_id), \"\\n\")\n",
    "\n",
    "# Get job related info\n",
    "print(client.get_job_info(submission_id), \"\\n\")\n",
    "\n",
    "# Get the job's logs\n",
    "print(client.get_job_logs(submission_id))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Iterate through the logs of a job \n",
    "async for lines in client.tail_job_logs(submission_id):\n",
    "    print(lines, end=\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Delete a job"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(client.list_jobs())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "client.stop_job(submission_id)\n",
    "\n",
    "client.delete_job(submission_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(client.list_jobs())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "cluster.down()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
